{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32228a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSingleFile( tfile, treename, flatenndf=False ):\n",
    "    ttree = uproot.open(tfile)\n",
    "    data = pd.DataFrame(ttree[treename].arrays(library=\"np\"))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27e41b",
   "metadata": {},
   "source": [
    "## Prepare data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARE DATA ####\n",
    "RUN = 13269\n",
    "PERIOD = \"Run_4\"\n",
    "PECUT = 300\n",
    "\n",
    "SHOW_TRACKS = False\n",
    "DUMP = False\n",
    "\n",
    "# Choose PMT timing field: \"pmt_time_start\" or \"pmt_time_rise\" or \"pmt_time\" (legacy)\n",
    "PMT_TIME_FIELD = \"pmt_time_rise\"\n",
    "\n",
    "TDEF = \"rise\"\n",
    "if \"start\" in PMT_TIME_FIELD:\n",
    "    TDEF = \"start\"\n",
    "if \"pmt_time\" in PMT_TIME_FIELD:\n",
    "    TDEF = \"start\"\n",
    "\n",
    "PATH = \"/exp/icarus/data/users/mvicenzi/pmt-calibration/track_matches/\"\n",
    "OUTPATH = \"/exp/icarus/data/users/mvicenzi/pmt-calibration/residualsdb/\" + PERIOD + \"/\"\n",
    "COSMICSDB = \"/exp/icarus/data/users/mvicenzi/pmt-database/pmt_cosmics_timing_data/\"\n",
    "LASERDB = \"/exp/icarus/data/users/mvicenzi/pmt-database/pmt_laser_timing_data/\"\n",
    "\n",
    "FILENAME = PATH + \"run{}_matched_light_tracks.root\".format(RUN)\n",
    "\n",
    "APPLY_LASER = False\n",
    "#LASERCORR = LASERDB + \"pmt_laser_timing_data_run08046_from8270-8304.csv\"\n",
    "LASERCORR = LASERDB + \"pmt_laser_timing_data_run09301_from9305.csv\"\n",
    "#LASERCORR = LASERDB + \"pmt_laser_timing_data_run09773_from9773.csv\"\n",
    "#LASERCORR = LASERDB + \"pmt_laser_timing_data_run10908_from10982.csv\"\n",
    "#LASERCORR = LASERDB + \"pmt_laser_timing_data_run11590_from11641.csv\"\n",
    "#LASERCORR = LASERDB + \"pmt_laser_timing_data_run12837_from12838.csv\"\n",
    "\n",
    "APPLY_COSMICS = False\n",
    "COSMICSCORR = COSMICSDB + \"pmt_cosmics_timing_data_run09301_from9337.csv\"\n",
    "#COSMICSCORR = COSMICSDB + \"pmt_cosmics_timing_data_run09773_from10085.csv\"\n",
    "#COSMICSCORR = COSMICSDB + \"pmt_cosmics_timing_data_run08046_from8461.csv\"\n",
    "#COSMICSCORR = OUTPATH + \"run12014_residuals_laseronly.csv\"\n",
    "#COSMICSCORR = OUTPATH + \"run9337_residuals_laseronly.csv\"\n",
    "#COSMICSCORR = OUTPATH + \"run10085_residuals_laseronly.csv\"\n",
    "#COSMICSCORR = OUTPATH + \"run11813_residuals_laseronly.csv\"\n",
    "#COSMICSCORR = OUTPATH + \"run12970_residuals_laseronly.csv\"\n",
    "\n",
    "suffix = \"nocorr\"\n",
    "if APPLY_LASER:\n",
    "    suffix = \"laseronly\"\n",
    "if APPLY_LASER and APPLY_COSMICS:\n",
    "    suffix = \"lasercosmics\"\n",
    "\n",
    "OUTFILE = OUTPATH + \"run{}_residuals_{}_{}_{}.csv\".format(RUN,TDEF,TYPE,suffix)\n",
    "\n",
    "print(\"Reading {}\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08362026",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get optical data\n",
    "dfw = loadSingleFile(FILENAME, \"trackLightMatchW\")\n",
    "dfe = loadSingleFile(FILENAME, \"trackLightMatchE\")\n",
    "df = pd.concat([dfe, dfw])\n",
    "del dfw\n",
    "del dfe\n",
    "\n",
    "print(\"Considering {} track-flash matches\".format( len(df) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563675c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e361a",
   "metadata": {},
   "source": [
    "## Check tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TRACKS:\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 4.3),dpi=200)\n",
    "\n",
    "    #ax[0].plot( [df.track_end_z, df.track_start_z], [df.track_end_y, df.track_start_y], color='black', lw=0.1 )\n",
    "    ax[0].axhline(y=125., linestyle=\"dashed\")\n",
    "    ax[0].axhline(y=-175., linestyle=\"dashed\")\n",
    "\n",
    "    ax[1].axvline(x=209., linestyle=\"dotted\", color=\"C1\", label=\"Cathode\")\n",
    "    ax[1].axvline(x=-209., linestyle=\"dotted\", color=\"C1\")\n",
    "    #ax[1].plot( [df.track_end_x, df.track_start_x], [df.track_end_y, df.track_start_y], color='black', lw=0.1 )\n",
    "    ax[1].axhline(y=125., linestyle=\"dashed\")\n",
    "    ax[1].axhline(y=-175., linestyle=\"dashed\")\n",
    "\n",
    "    # consider steeper angles?\n",
    "    _sel_dir_z= (df.track_dir_z > -0.25) & (df.track_dir_z < 0.25 ) \n",
    "    _sel_dir_x = (df.track_dir_x > -0.1) & (df.track_dir_x < 0.1 )\n",
    "    _seldir= _sel_dir_z\n",
    "    ax[0].plot( [df[_seldir].track_end_z, df[_seldir].track_start_z], [df[_seldir].track_end_y, df[_seldir].track_start_y], color='black', lw=0.1 )\n",
    "    ax[1].plot( [df[_seldir].track_end_x, df[_seldir].track_start_x], [df[_seldir].track_end_y, df[_seldir].track_start_y], color='black', lw=0.1 )\n",
    "    print( len(df), len(df[_seldir]) )\n",
    "\n",
    "    ax[0].set_ylabel(\"Y [cm]\" )  \n",
    "    ax[0].set_xlabel(\"Z [cm]\" )\n",
    "    ax[0].grid(alpha=0.5)\n",
    "\n",
    "    ax[1].set_ylabel(\"Y [cm]\" )  \n",
    "    ax[1].set_xlabel(\"X [cm]\" ) \n",
    "    ax[1].grid(alpha=0.5)\n",
    "\n",
    "    watermark = r'$\\mathbf{ICARUS}\\,$ Data' +' - Run {}'.format(RUN)\n",
    "    ax[0].text(0.01, 1.05, watermark, fontsize=12, color='black', alpha=1,\n",
    "         ha='left', va='center', transform=ax[0].transAxes)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    # save the image as pdf!\n",
    "    #savepath = \"figs/tracks/run{}_tracks_standard_selection.pdf\".format(RUN)\n",
    "    #print(\"Saving to {}...\".format(savepath))\n",
    "    #plt.savefig(savepath,dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b6101",
   "metadata": {},
   "source": [
    "## Explode the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explode the dataframe \n",
    "df = df.explode([PMT_TIME_FIELD, \"pmt_x\", \"pmt_y\", \"pmt_pe\", \"pmt_z\", \"pmt_amplitude\",\"channel_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00850c81",
   "metadata": {},
   "source": [
    "## Add timing corrections (if needed!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ea37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and use laser correction\n",
    "## WARNING: DO NOT USE IF CORRECTIONS WERE ALREADY APPLIED AT PREVIOUS STAGES\n",
    "## note: laser corrections are in ns!\n",
    "\n",
    "lasercorr = pd.read_csv(LASERCORR, sep=r'\\s*,\\s*', engine='python')\n",
    "lasercorr = lasercorr.rename(columns={'channel': 'channel_id'})\n",
    "lasercorr.set_index([\"channel_id\"], inplace=True)\n",
    "lasercorr[\"t_signal\"] = lasercorr[\"t_signal\"]/1e3  #convert ns to us\n",
    "\n",
    "df = df.join( lasercorr[[\"t_signal\"]], on=[\"channel_id\"])\n",
    "\n",
    "if APPLY_LASER:\n",
    "    print(\"Applying laser corrections from {}...\".format(LASERCORR))\n",
    "    df[PMT_TIME_FIELD] = df[PMT_TIME_FIELD] - df['t_signal']  #CURRENTLY ADDING LASER CORRECTIONS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and use cosmic corrections\n",
    "## WARNING: DO NOT USE IF CORRECTIONS WERE ALREADY APPLIED AT PREVIOUS STAGES\n",
    "## note: cosmics corrections are in ns!\n",
    "\n",
    "cosmicscorr = pd.read_csv(COSMICSCORR, sep=r'\\s*,\\s*', engine='python')\n",
    "cosmicscorr = cosmicscorr.rename(columns={'channel': 'channel_id'})\n",
    "cosmicscorr.set_index([\"channel_id\"])\n",
    "cosmicscorr[\"mean_residual_ns\"] = cosmicscorr[\"mean_residual_ns\"]/1e3  #convert ns to us\n",
    "\n",
    "df = df.join( cosmicscorr[[\"mean_residual_ns\"]], on=[\"channel_id\"])\n",
    "\n",
    "if APPLY_COSMICS:\n",
    "    print(\"Applying cosmics corrections from {}...\".format(COSMICSCORR))\n",
    "    df[PMT_TIME_FIELD] = df[PMT_TIME_FIELD] - df['mean_residual_ns']  #CURRENTLY ADDING COSMICS CORRECTIONS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5af878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df[\"pmt_pe\"]>150,[\"event\",\"cryo\",\"flash_id\",\"pmt_y\",\"channel_id\",\"pmt_time\",'t_signal','mean_residual_ns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30805d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneed columns\n",
    "df = df.drop(columns=[\"t_signal\"])\n",
    "df = df.drop(columns=[\"mean_residual_ns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2cb217",
   "metadata": {},
   "source": [
    "## Computing fit and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8645429",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sel = (df.pmt_pe > PECUT)\n",
    "meandf = df[_sel][[\"run\", \"event\", \"cryo\", \"flash_id\", PMT_TIME_FIELD, \"pmt_pe\", \"pmt_y\"]].groupby([\"run\", \"event\", \"cryo\", \"flash_id\", \"pmt_y\"]).apply( \n",
    "    lambda x : pd.Series( {\n",
    "        \"mean_time\" : np.mean(x[PMT_TIME_FIELD]),\n",
    "        \"weight_mean_time\" : np.average(x[PMT_TIME_FIELD], weights=x.pmt_pe), \n",
    "        \"error_mean_time\": np.std(x[PMT_TIME_FIELD]) / np.sqrt(len(x[PMT_TIME_FIELD])),\n",
    "        \"n_measurements\": len(x), #number of element at this quota\n",
    "    }) ).reset_index()\n",
    "\n",
    "meandf = meandf.groupby([\"run\", \"event\", \"cryo\", \"flash_id\"]).agg(list)\n",
    "\n",
    "print(\"PE cut leaves {} tracks\".format( len(meandf) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4 # minimum number of quotas available for a good fit (at least 1 pmt >PECUT in each)\n",
    "MIN_MEASUREMENTS_PER_QUOTA = 1  # Average measurements per quota\n",
    "meandf = meandf[meandf[\"pmt_y\"].apply(lambda x: isinstance(x, (list, np.ndarray)) and len(x) >= N)]\n",
    "\n",
    "print(\"Minimum quotas cut leaves {} tracks\".format( len(meandf ) ))\n",
    "\n",
    "# Filter fits by all quotas with min measurements\n",
    "meandf = meandf[meandf.apply(lambda x: min(x.n_measurements) >= MIN_MEASUREMENTS_PER_QUOTA if isinstance(x.n_measurements, (list, np.ndarray)) else False, axis=1)]\n",
    "\n",
    "print(\"Minimum measurements per quota cut leaves {} tracks\".format( len(meandf ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meandf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b23d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdiff( y, t):\n",
    "    # max y is on top : cosmics are going towards decreasing y \n",
    "    return t[np.argmin(y)] - t[np.argmax(y)]\n",
    "\n",
    "# Define a linear model: t = intercept + slope * y\n",
    "def linear_model(x, intercept, slope):\n",
    "    return intercept + slope * x\n",
    "\n",
    "def fittime( y, t ):\n",
    "\n",
    "    if(len(y)<4 or len(t)<4):\n",
    "        print(\"Not enough data points for linear regression: y = %s, t = %s\", y, t)\n",
    "        return 0,0,0\n",
    "    \n",
    "    # initial guess\n",
    "    y_range = np.max(y) - np.min(y)\n",
    "    slope0 = (np.max(t) - np.min(t)) / y_range if y_range !=0 else 0\n",
    "    intercept0 = np.median(t) - slope0 * np.median(y)\n",
    "    initp0 = [intercept0, slope0]\n",
    "\n",
    "    try:\n",
    "\n",
    "        popt, _ = curve_fit(linear_model, y, t, p0=initp0)\n",
    "        return popt[0], popt[1], 1\n",
    "    \n",
    "        #old implementation... gave trouble for RUN-3..\n",
    "        #res= stats.linregress(y, t)\n",
    "        #return res.intercept,  res.slope\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Fitting failed:\", e)\n",
    "        return 0,0,0\n",
    "\n",
    "def residuals( tobs, y, a, b ):\n",
    "    return tobs -  ( a + b*y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd66c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "meandf[\"diff_time\"] = meandf.apply( lambda x : getdiff( x.pmt_y, x.mean_time ), axis=1 ) \n",
    "meandf[[\"intercept\", \"slope\", \"status\"]] = meandf.apply(lambda x : fittime(x.pmt_y, x.mean_time ), axis=1, result_type=\"expand\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d99195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meandf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting fit back in the exploded dataframe, then compute the residual\n",
    "# This should work for every channel_id\n",
    "# this is using all slopes, including possible \"negative\" ones\n",
    "dfg = df.join( meandf[[\"intercept\", \"slope\", \"status\"]], on=[\"run\", \"event\", \"cryo\", \"flash_id\"], how='inner')\n",
    "\n",
    "# TEST: only positive slopes\n",
    "#dfg = df.join( meandf[meandf.slope<0][[\"intercept\", \"slope\"]], on=[\"run\", \"event\", \"cryo\", \"flash_id\"], how='inner')\n",
    "\n",
    "dfg[\"residuals\"] = dfg.apply( lambda x : residuals(x[PMT_TIME_FIELD], x.pmt_y, x.intercept, x.slope), axis=1 ) \n",
    "\n",
    "# Keep only the residuals on relevant PMT for that event\n",
    "dfg = dfg[(dfg.pmt_pe>PECUT) & (dfg.status>0)] #& (dfg.residuals<1) & (dfg.residuals>-1)]\n",
    "\n",
    "# Identify ALL fits that contain any big outlier\n",
    "# Remove ENTIRE fits\n",
    "RESIDUAL_OUTLIER_THRESHOLD=0.030 # us\n",
    "bad_fits = dfg[dfg['residuals'].abs() > RESIDUAL_OUTLIER_THRESHOLD].groupby([\"run\", \"event\", \"cryo\", \"flash_id\"]).size().index.tolist()\n",
    "dfg = dfg[~dfg[[\"run\", \"event\", \"cryo\", \"flash_id\"]].apply(tuple, axis=1).isin(bad_fits)]\n",
    "\n",
    "print(\"Flash-tracks used for the computation of residuals: {}\".format( len(dfg.groupby([\"run\", \"event\", \"cryo\", \"flash_id\"])) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DUMP:\n",
    "    print(\"Dumping exploded fit results...\")\n",
    "    dfg.to_csv(\"dumps/DUMP_run{}_{}_{}_{}.csv\".format(RUN,TDEF,TYPE,suffix), index=False, float_format='%.6e')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da68dd",
   "metadata": {},
   "source": [
    "## Group and save residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now group the residual by channel, computing the mean residual for each of them\n",
    "# this is the final output which can then be saved!\n",
    "us_to_ns = 1e3\n",
    "thisdfg = dfg.groupby([\"channel_id\"]).apply(\n",
    "    lambda x : pd.Series( { \n",
    "            'x': np.mean(x.pmt_x),\n",
    "            'y': np.mean(x.pmt_y),\n",
    "            'z': np.mean(x.pmt_z),\n",
    "            'entries' : int(len(x.residuals)), \n",
    "            'pecut' : PECUT,\n",
    "            'mean_residual_ns' : np.mean(x.residuals)*us_to_ns,\n",
    "            'median_residual_ns' : np.median(x.residuals)*us_to_ns,\n",
    "            'std_residual_ns' : np.std(x.residuals)*us_to_ns,\n",
    "            'emean_ns' : np.std(x.residuals)*us_to_ns/len(x.residuals)\n",
    "        })).reset_index()\n",
    "\n",
    "thisdfg['entries'] = thisdfg['entries'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisdfg.head(10)\n",
    "#print(len(thisdfg))\n",
    "#print(360-len(thisdfg))\n",
    "#print(np.unique(thisdfg.channel_id.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving residuals to {}...\".format(OUTFILE))\n",
    "thisdfg.to_csv(OUTFILE, index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d61caf2",
   "metadata": {},
   "source": [
    "#### Add lines with PMTs that are off (for DB files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.read_csv(OUTFILE)\n",
    "\n",
    "# list of PMT channels at 0 voltage from HV files + disconnected pmts:\n",
    "offCHs = []\n",
    "if PERIOD == \"Run_2\" or PERIOD==\"Run_1\":\n",
    "    offCHs = [350, 248, 215, 190, 161, 139, 127, 103, 131, 59, 52, 21, 5, 71]\n",
    "else: # for Run_3 onwards...\n",
    "    offCHs = [215, 103, 71 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPlacements(file=\"./pmt_positions.csv\"):\n",
    "    geo = pd.read_csv(file,sep=\",\")\n",
    "    geo.drop(columns=[\"entry\",\"subentry\"],inplace=True)\n",
    "    return geo\n",
    "\n",
    "geo = readPlacements(file=\"./pmt_positions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'channel_id':[ a for a in offCHs],\n",
    "        'x':[ geo[\"pmt_x\"].iloc[a] for a in offCHs],\n",
    "        'y':[ geo[\"pmt_y\"].iloc[a] for a in offCHs],\n",
    "        'z':[ geo[\"pmt_z\"].iloc[a] for a in offCHs],\n",
    "        'entries': [ 0 for a in offCHs],\n",
    "        'pecut': [ 0. for a in offCHs],\n",
    "        'mean_residual_ns': [ 0. for a in offCHs],\n",
    "        'std_residual_ns': [ 0. for a in offCHs],\n",
    "        'emean_ns': [ 0. for a in offCHs]        \n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c950cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "addf = pd.DataFrame(dictionary)\n",
    "rdf = pd.concat([rdf,addf], ignore_index=True)\n",
    "rdf.sort_values(by=\"channel_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88352d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.to_csv(OUTFILE, index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db44e4",
   "metadata": {},
   "source": [
    "## Looking at some residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2daf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channel = 60\n",
    "residuals = dfg[dfg.channel_id==selected_channel].residuals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "lab = \"Channel ID \"+str(selected_channel)+\"\\n\"\n",
    "lab += \"Entries: {}\\n\".format(len(residuals))\n",
    "lab += \"Mean: {:.2f} ns\\n\".format(np.nanmean(residuals*1e3))\n",
    "lab += \"Std: {:.2f} ns\".format(np.nanstd(residuals*1e3))\n",
    "\n",
    "plt.hist( residuals*1e3, bins=50, histtype='step', range=(-10,10), label=lab)\n",
    "#plt.ylabel(\"# entries\", fontsize=16)\n",
    "plt.xlabel(\"Residuals [ns]\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.grid(linestyle=\"dashed\", alpha=0.5)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.savefig(\"figs/run{}_channel_{}_residuals_test.pdf\".format(RUN,selected_channel),dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisdfg[thisdfg.mean_residual_ns > 10].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155457c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting full distribution \n",
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "rmin=-10\n",
    "rmax=12\n",
    "r=(rmin,rmax)\n",
    "s=0.5\n",
    "b=int((rmax-rmin)/s)\n",
    "\n",
    "res = thisdfg.mean_residual_ns.to_numpy()\n",
    "lab = \"Run {}\\nMean: {:.2f} ns\\nStd: {:.2f} ns\".format(RUN,np.nanmean(res),np.nanstd(res))\n",
    "\n",
    "plt.hist(res, bins=b, linewidth=2, range=r, histtype=\"step\", label=lab)\n",
    "\n",
    "plt.xlabel(\"Time residual [ns]\")\n",
    "plt.ylabel(\"# PMTs\")\n",
    "plt.legend()\n",
    "plt.grid(linestyle=\"dashed\", alpha=0.5)\n",
    "#plt.savefig(\"figs/run{}_residuals_test.png\".format(RUN),dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87151a",
   "metadata": {},
   "source": [
    "## Looking at slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = meandf[\"slope\"].values\n",
    "len(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf14244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "plt.hist( slopes*1e3, bins=50, range=(-0.1,0.075), histtype='step')\n",
    "plt.ylabel(\"# Flash-Track matches\", fontsize=14)\n",
    "plt.xlabel(\"Fitted slope [cm ns$^{-1}$]\", fontsize=14)\n",
    "\n",
    "plt.axvline(x=0.,color=\"red\",linestyle=\"dotted\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.grid(linestyle=\"dashed\",alpha=0.5)\n",
    "#plt.legend()\n",
    "#plt.savefig(\"figs/run{}_slope_distribution_test.png\".format(RUN),dpi=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35be95b-5b10-4c77-8f43-124bcb630740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
